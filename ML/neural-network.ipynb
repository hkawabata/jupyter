{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot(classifier, data, labels, title=None, xlabel=None, ylabel=None):\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'cyan'][:len(unique_labels)]\n",
    "    x1max, x1min = np.max(data[:, 0]), np.min(data[:, 0])\n",
    "    x2max, x2min = np.max(data[:, 1]), np.min(data[:, 1])\n",
    "    scale_x1 = x1max - x1min\n",
    "    scale_x2 = x2max - x2min\n",
    "    x1max, x1min = x1max + (x1max-x1min)*0.05, x1min - (x1max-x1min)*0.05\n",
    "    x2max, x2min = x2max + (x2max-x2min)*0.05, x2min - (x2max-x2min)*0.05\n",
    "    resolution = scale_x1 / 200\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, resolution), np.arange(x2min, x2max, resolution))\n",
    "    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    print(z.shape)\n",
    "    print(np.array([xx1.ravel(), xx2.ravel()]).T.shape)\n",
    "    z = z.reshape(xx1.shape)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)\n",
    "    plt.contourf(xx1, xx2, z, alpha=0.4, cmap=ListedColormap(colors))\n",
    "    \n",
    "    data_of_each_label = {}\n",
    "    for d, l in zip(data, labels):\n",
    "        if l in data_of_each_label:\n",
    "            data_of_each_label[l].append(d)\n",
    "        else:\n",
    "            data_of_each_label[l] = [d]\n",
    "    \n",
    "    for i in range(len(unique_labels)):\n",
    "        data = data_of_each_label[unique_labels[i]]\n",
    "        plt.scatter(np.array(data)[:, 0], np.array(data)[:, 1], s=5, c=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6355250354179524e-11\n",
      "5.761544261041627e-11\n",
      "5.504543476055314e-11\n",
      "5.818024086557062e-11\n",
      "5.87638421222345e-11\n",
      "5.933120406880137e-11\n",
      "5.6577580975985505e-11\n",
      "5.4939783825491856e-11\n",
      "5.4642559750716556e-11\n",
      "6.114609984728244e-11\n",
      "5.6790202298076756e-11\n",
      "5.960829544343667e-11\n",
      "5.268388973340178e-11\n",
      "6.49604178460024e-11\n",
      "5.5368462546774666e-11\n",
      "5.7035774561438773e-11\n",
      "5.633441084262457e-11\n",
      "6.119245097849328e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class MLPLayer(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Affine(MLPLayer):\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "        self.dW = None\n",
    "        self.A_with_bias = None\n",
    "\n",
    "    def forward(self, A):\n",
    "        self.A_with_bias = np.full((A.shape[0]+1, A.shape[1]), 1.0)\n",
    "        self.A_with_bias[1:] = A\n",
    "        out = np.dot(self.W, self.A_with_bias)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dA = np.dot(self.W.T[1:], dout)\n",
    "        self.dW = np.dot(dout, self.A_with_bias.T)\n",
    "        return dA\n",
    "\n",
    "\n",
    "class Sigmoid(MLPLayer):\n",
    "    def __init__(self):\n",
    "        self.sigmoid = None\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        self.sigmoid = 1.0 / (1.0 + np.exp(-Z))\n",
    "        return self.sigmoid\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dphi = self.sigmoid * (1.0 - self.sigmoid)\n",
    "        dZ = dout * dphi\n",
    "        return dZ\n",
    "\n",
    "\n",
    "class HyperbolicTangent(MLPLayer):\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        out = np.tanh(Z)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dphi = 1.0 / np.cosh(self.Z)**2\n",
    "        dZ = dout * dphi\n",
    "        return dZ\n",
    "\n",
    "\n",
    "class ReLU(MLPLayer):\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        self.mask = Z <= 0\n",
    "        out = Z.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dphi = np.full(self.mask.shape, 1.0)\n",
    "        dphi[self.mask] = 0\n",
    "        dZ = dout * dphi\n",
    "        return dZ\n",
    "\n",
    "\n",
    "class SoftMax(MLPLayer):\n",
    "    def __init__(self):\n",
    "        self.Y = None\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        Z_exp = np.exp(Z)\n",
    "        self.Y = Z_exp / Z_exp.sum(axis=0)\n",
    "        return self.Y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dZ = self.Y * (dout - np.sum(self.Y * dout, axis=0))\n",
    "        return dZ\n",
    "\n",
    "\n",
    "class CostCalculation(MLPLayer):\n",
    "    def __init__(self):\n",
    "        self.Y_predict = None\n",
    "        self.Y_correct = None\n",
    "    \n",
    "    def forward(self, Y_predict, Y_correct):\n",
    "        self.Y_predict = Y_predict\n",
    "        self.Y_correct = Y_correct\n",
    "        cost = - np.sum(Y_correct * np.log(Y_predict) + (1.0 - Y_correct) * np.log(1.0 - Y_predict), axis=0)\n",
    "        cost = np.average(cost)\n",
    "        return cost\n",
    "    \n",
    "    def backward(self, dout=1.0):\n",
    "        batch_size = self.Y_predict.shape[1]\n",
    "        dA = (self.Y_predict - self.Y_correct) / (self.Y_predict * (1.0 - self.Y_predict)) / batch_size\n",
    "        return dA\n",
    "\n",
    "\n",
    "class BatchNormalization(MLPLayer):\n",
    "    def __init__(self, h_units, eps=1e-8, gamma=1.0, beta=0):\n",
    "        self.h_units = h_units\n",
    "        self.eps = eps\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.std = None\n",
    "        self.Z_norm = None\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        mu = np.average(Z, axis=0)\n",
    "        self.std = np.std(Z, axis=0)\n",
    "        self.Z_norm = (Z - mu) / np.sqrt(self.std**2 + self.eps)\n",
    "        out = self.gamma * self.Z_norm + self.beta\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dgamma = (dout * self.Z_norm).sum(axis=0)\n",
    "        self.dbeta = dout.sum(axis=0)\n",
    "        dZ = self.gamma / (self.h_units * np.sqrt(self.std**2 + self.eps)) * (\n",
    "            self.h_units * dout - self.dbeta - self.Z_norm * self.dgamma\n",
    "        )\n",
    "        return dZ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMLPClassifier:\n",
    "    def __init__(self, h_layers, h_units, epochs, eta, n_batch, l2=0.,\n",
    "                 hidden_activation_class=HyperbolicTangent, debug_grad_check=False, debug_activation_hist=False):\n",
    "        self.h_layers = h_layers\n",
    "        self.h_units = h_units\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.n_batch = n_batch\n",
    "        self.l2 = l2\n",
    "        self.hidden_activation_class = hidden_activation_class\n",
    "        self.layers = None\n",
    "        self.cost_layer = None\n",
    "        self.index2label = None\n",
    "        self.label2index = None\n",
    "        self.n = None\n",
    "        self.m = None\n",
    "        self.t = None\n",
    "        self.cost = None\n",
    "        self.mse = None\n",
    "        self.debug_grad_check = debug_grad_check\n",
    "        self.grad_err = []\n",
    "        self.debug_activation_hist = debug_activation_hist\n",
    "        self.activation_hist = []\n",
    "    \n",
    "    def predict(self, data):\n",
    "        out = np.matrix(data).T\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        i_label = np.argmax(out, axis=0)\n",
    "        return self.index2label[i_label]\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        self.index2label = np.unique(labels)\n",
    "        self.label2index = {self.index2label[i]: i for i in range(len(self.index2label))}\n",
    "        self.n = len(data)\n",
    "        self.m = len(data[0])\n",
    "        self.t = len(self.index2label)\n",
    "        \n",
    "        X = data.T\n",
    "        Y = np.zeros([self.t, self.n])\n",
    "        for i in range(self.n):\n",
    "            l = labels[i]\n",
    "            Y[self.label2index[l]][i] = 1.0\n",
    "        \n",
    "        # 重みの初期化\n",
    "        W = []\n",
    "        W.append(np.random.randn(self.h_units, self.m+1) * np.sqrt(1.0/(self.m+1)))\n",
    "        for i in range(self.h_layers-1):\n",
    "            W.append(np.random.randn(self.h_units, self.h_units+1) * np.sqrt(1.0/(self.h_units+1)))\n",
    "        W.append(np.random.randn(self.t, self.h_units+1) * np.sqrt(1.0/(self.h_units+1)))\n",
    "        \n",
    "        # レイヤの初期化\n",
    "        self.layers = []\n",
    "        for i in range(self.h_layers):\n",
    "            self.layers.append(Affine(W[i]))\n",
    "            self.layers.append(BatchNormalization(self.h_units))\n",
    "            self.layers.append(self.hidden_activation_class())\n",
    "        self.layers.append(Affine(W[-1]))\n",
    "        self.layers.append(SoftMax())\n",
    "        self.cost_layer = CostCalculation()\n",
    "        \n",
    "        self.cost = []\n",
    "        self.mse = []\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            for _ in range(len(data) // self.n_batch):\n",
    "                # ミニバッチデータ選択\n",
    "                ids = np.random.choice(range(self.n), self.n_batch, replace=False)\n",
    "                X_part = X[:, ids]\n",
    "                Y_part = Y[:, ids]\n",
    "            \n",
    "                self.__cycle(X_part, Y_part)\n",
    "            \n",
    "            \"\"\"\n",
    "            # フォワードプロパゲーション\n",
    "            out = X_part\n",
    "            if self.debug_activation_hist:\n",
    "                # デバッグ: 活性化関数の出力分布\n",
    "                self.activation_hist.append([])\n",
    "            for layer in self.layers:\n",
    "                out = layer.forward(out)\n",
    "                if self.debug_activation_hist and isinstance(layer, self.hidden_activation_class):\n",
    "                    # デバッグ: 活性化関数の出力分布\n",
    "                    self.activation_hist[-1].append(np.histogram(out, bins=20))\n",
    "            cost = self.cost_layer.forward(out, Y_part)\n",
    "            self.cost.append(cost)\n",
    "            \n",
    "            # 誤差計算\n",
    "            mse = np.sum((Y_part - out)**2) / self.n_batch\n",
    "            self.mse.append(mse)\n",
    "            if mse < 1e-3:\n",
    "                break\n",
    "        \n",
    "            # バックプロパゲーション\n",
    "            dout = self.cost_layer.backward()\n",
    "            for layer in self.layers[::-1]:\n",
    "                dout = layer.backward(dout)\n",
    "            \n",
    "            # L2正則化項を勾配に追加\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, Affine):\n",
    "                    layer.dW += self.l2 * layer.W\n",
    "                elif isinstance(layer, BatchNormalization):\n",
    "                    layer.dgamma += self.l2 * layer.gamma\n",
    "                    layer.dbeta += self.l2 * layer.beta\n",
    "            \n",
    "            # デバッグ: Gradient Checking\n",
    "            if self.debug_grad_check:\n",
    "                grad = [layer.dW for layer in self.layers if isinstance(layer, Affine)]\n",
    "                self.__check_gradient(X_part, Y_part, grad)\n",
    "            \n",
    "            # パラメータの更新\n",
    "            self.__update()\n",
    "            \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __cycle(self, X, Y):\n",
    "        # フォワードプロパゲーション\n",
    "        out = X\n",
    "        for layer in self.layers:\n",
    "            #out = layer.forward(out, is_training=True)\n",
    "            out = layer.forward(out)\n",
    "        cost = self.cost_layer.forward(out, Y)\n",
    "        \n",
    "        # バックプロパゲーション\n",
    "        dout = self.cost_layer.backward()\n",
    "        dx = dout.copy()\n",
    "        for layer in reversed(self.layers):\n",
    "            dx = layer.backward(dx)\n",
    "        \n",
    "        # L2正則化項を勾配に追加\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Affine):\n",
    "                layer.dW += self.l2 * layer.W\n",
    "            elif isinstance(layer, BatchNormalization):\n",
    "                layer.dgamma += self.l2 * layer.gamma\n",
    "                layer.dbeta += self.l2 * layer.beta\n",
    "            #elif isinstance(layer, Convolution):\n",
    "            #    layer.dF += self.l2 * layer.filters\n",
    "            #    layer.db += self.l2 * layer.bias\n",
    "        \n",
    "        # デバッグ: Gradient Checking\n",
    "        if self.debug_grad_check:\n",
    "            grad = [layer.dW for layer in self.layers if isinstance(layer, Affine)]\n",
    "            self.__check_gradient(X, Y, grad)\n",
    "        \n",
    "        # 重みの更新\n",
    "        self.__update()\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __update(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Affine):\n",
    "                layer.W -= self.eta * layer.dW\n",
    "            elif isinstance(layer, BatchNormalization):\n",
    "                layer.gamma -= self.eta * layer.dgamma.sum()\n",
    "                layer.beta -= self.eta * layer.dbeta.sum()\n",
    "\n",
    "    def __check_gradient(self, X, Y, grad):\n",
    "        \"\"\"\n",
    "        Gradient Checking\n",
    "        - デバッグ用メソッド\n",
    "        - 誤差伝播による微分と数値微分を比較する\n",
    "        \"\"\"\n",
    "        layers_tmp = copy.deepcopy(self.layers)\n",
    "        cost_layer_tmp = copy.deepcopy(self.cost_layer)\n",
    "        eps = 1e-5\n",
    "        grad_num = []\n",
    "        for l in range(len(layers_tmp)):\n",
    "            if not isinstance(layers_tmp[l], Affine):\n",
    "                continue\n",
    "            g = np.zeros(layers_tmp[l].W.shape)\n",
    "            for i in range(layers_tmp[l].W.shape[0]):\n",
    "                for j in range(layers_tmp[l].W.shape[1]):\n",
    "                    layers_tmp[l].W[i][j] -= eps\n",
    "                    out = X\n",
    "                    for layer in layers_tmp:\n",
    "                        out = layer.forward(out)\n",
    "                    cost1 = cost_layer_tmp.forward(out, Y) + layers_tmp[l].W[i][j]**2 * self.l2 / 2.0 # 正則化項は差分があるもののだけを加える\n",
    "                    layers_tmp[l].W[i][j] += eps\n",
    "                    \n",
    "                    layers_tmp[l].W[i][j] += eps\n",
    "                    out = X\n",
    "                    for layer in layers_tmp:\n",
    "                        out = layer.forward(out)\n",
    "                    cost2 = cost_layer_tmp.forward(out, Y) + layers_tmp[l].W[i][j]**2 * self.l2 / 2.0\n",
    "                    layers_tmp[l].W[i][j] -= eps\n",
    "                    \n",
    "                    g[i][j] = (cost2 - cost1) / eps / 2.0\n",
    "            grad_num.append(g)\n",
    "        vec_grad_num = np.hstack(tuple([g.flatten() for g in grad_num]))\n",
    "        vec_grad = np.hstack(tuple([g.flatten() for g in grad]))\n",
    "        relative_err = np.linalg.norm(vec_grad_num-vec_grad) / (np.linalg.norm(vec_grad_num) + np.linalg.norm(vec_grad))\n",
    "        self.grad_err.append(relative_err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 勾配確認\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# データ作成\n",
    "def circle(c_, R_, n_):\n",
    "    r = R_ * np.random.rand(n_)\n",
    "    theta = np.random.rand(n_) * 2 * np.pi\n",
    "    data = np.array([r * np.sin(theta) + c_[0], r * np.cos(theta) + c_[1]]).T\n",
    "    return data\n",
    "\n",
    "N = 300\n",
    "data = np.concatenate([\n",
    "    circle([0, 0], 2, N//4),\n",
    "    circle([-4, 2], 1.5, N//4),\n",
    "    circle([3, 4], 2.5, N//4),\n",
    "    circle([-2, 7], 2, N//4)\n",
    "])\n",
    "labels = np.concatenate([\n",
    "    np.full(N//4, 0),\n",
    "    np.full(N//4, 1),\n",
    "    np.full(N//4, 2),\n",
    "    np.full(N//4, 3)\n",
    "])\n",
    "\n",
    "\n",
    "# 学習の設定\n",
    "H_LAYERS = 5\n",
    "H_UNITS = 10\n",
    "\n",
    "mlp = SimpleMLPClassifier(h_layers=H_LAYERS, h_units=H_UNITS, epochs=3, eta=0.01, n_batch=50, l2=0.5, debug_grad_check=True)\n",
    "#mlp.fit(data, labels, data, labels)\n",
    "mlp.fit(data, labels)\n",
    "for err in mlp.grad_err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.555693750849718e-11\n",
      "6.090805412152502e-11\n",
      "6.19145440682858e-11\n",
      "5.941352618664384e-11\n",
      "6.148354908095618e-11\n",
      "5.883371757060167e-11\n",
      "5.778775241465668e-11\n",
      "5.845993763214261e-11\n",
      "6.055602178837445e-11\n",
      "6.078429142771246e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# データ作成\n",
    "def circle(c_, R_, n_):\n",
    "    r = R_ * np.random.rand(n_)\n",
    "    theta = np.random.rand(n_) * 2 * np.pi\n",
    "    data = np.array([r * np.sin(theta) + c_[0], r * np.cos(theta) + c_[1]]).T\n",
    "    return data\n",
    "\n",
    "N = 300\n",
    "data = np.concatenate([\n",
    "    circle([0, 0], 2, N//4),\n",
    "    circle([-4, 2], 1.5, N//4),\n",
    "    circle([3, 4], 2.5, N//4),\n",
    "    circle([-2, 7], 2, N//4)\n",
    "])\n",
    "labels = np.concatenate([\n",
    "    np.full(N//4, 0),\n",
    "    np.full(N//4, 1),\n",
    "    np.full(N//4, 2),\n",
    "    np.full(N//4, 3)\n",
    "])\n",
    "\n",
    "\n",
    "# 学習の設定\n",
    "H_LAYERS = 5\n",
    "H_UNITS = 10\n",
    "\n",
    "mlp = SimpleMLPClassifier(h_layers=H_LAYERS, h_units=H_UNITS, epochs=1, eta=0.01, n_batch=50, l2=0.5, debug_grad_check=True)\n",
    "#mlp.fit(data, labels, data, labels)\n",
    "mlp.fit(data, labels)\n",
    "for err in mlp.grad_err:\n",
    "    print(err)\n",
    "\n",
    "#mlp = SimpleMLPClassifier(h_layers=H_LAYERS, h_units=H_UNITS, epochs=10000, eta=0.01, n_batch=50)\n",
    "#mlp.fit(data, labels, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49725,)\n",
      "(49725, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 決定領域描画のための自作関数\n",
    "plot(mlp, data, labels)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(range(len(mlp.acc_test)), mlp.acc_test)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        h, w = lines[0].split(',')\n",
    "        h, w = int(h), int(w)\n",
    "        for l in lines[1:]:\n",
    "            arr = l.split(',')\n",
    "            labels.append(arr[0])\n",
    "            data.append([float(v) for v in arr[1:]])\n",
    "        data = np.array(data).reshape(-1, 1, h, w)\n",
    "        labels = np.array(labels)\n",
    "    return data, labels\n",
    "\n",
    "data_train, labels_train = load_data('../data/mnist/mnist_train')\n",
    "data_test, labels_test = load_data('../data/mnist/mnist_test')\n",
    "\n",
    "# 時間がかかる場合はこちらの小さい方のデータを使う\n",
    "data_train_s, labels_train_s = data_train[:5000], labels_train[:5000]\n",
    "data_test_s, labels_test_s = data_test[:1000], labels_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 28, 28) Affine\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (128,1,28,28) into shape (128,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-dfee687cfcaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#cnn.fit(data_train, labels_train, data_test, labels_test)  # 1エポックに1分強かかる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-e1eb5e86133d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, labels_train, X_test, labels_test)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mX_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mY_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-e1eb5e86133d>\u001b[0m in \u001b[0;36m__cycle\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-cfabbf8f03b8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, A, is_training)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mA_with_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mA_with_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_with_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (128,1,28,28) into shape (128,1)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "#cnn = CNN(FN=30, FH=3, FW=3, PH=2, PW=2, h_units=100, h_layers=2, c_layers=2, epochs=20, eta=1e-1, n_batch=128, l2=0.,\n",
    "#          stride_filter=1, pad_filter=1, stride_pool=2, pad_pool=0)\n",
    "cnn = CNN(FN=30, FH=5, FW=5, PH=2, PW=2, h_units=100, h_layers=1, c_layers=1, epochs=20, eta=1e-1, n_batch=128, l2=1e-3,\n",
    "          stride_filter=1, pad_filter=0, stride_pool=2, pad_pool=0)\n",
    "\n",
    "#cnn.fit(data_train, labels_train, data_test, labels_test)  # 1エポックに1分強かかる\n",
    "cnn.fit(data_train_s, labels_train_s, data_test_s, labels_test_s)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Cost')\n",
    "plt.plot(range(len(cnn.cost)), cnn.cost)\n",
    "plt.grid()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(range(len(cnn.mse_train)), cnn.mse_train, label='train')\n",
    "plt.plot(range(len(cnn.mse_test)), cnn.mse_test, label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame([\n",
    "    cnn.predict(data_test[:20]),\n",
    "    labels_test[:20],\n",
    "    cnn.predict(data_test[:20]) == labels_test[:20]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine\n",
      "BatchNormalization\n",
      "ReLU\n",
      "Affine\n",
      "SoftMax\n"
     ]
    }
   ],
   "source": [
    "for l in cnn.layers:\n",
    "    print(l.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 犬猫画像読み込み\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMG_SIZE=128\n",
    "\n",
    "def load_cats_and_dogs_images(img_dir):\n",
    "    images_ = {'cat': [], 'dog': []}\n",
    "    for img_file in os.listdir(path=img_dir):\n",
    "        try:\n",
    "            img = Image.open(img_dir + '/' + img_file).convert('RGB').resize((IMG_SIZE, IMG_SIZE), Image.LANCZOS)\n",
    "            l = 'cat' if img_file[0].isupper() else 'dog'\n",
    "            images_[l].append(np.asarray(img).transpose(2, 0, 1))\n",
    "        except UnidentifiedImageError as e:\n",
    "            print(e)\n",
    "    for k, v in images_.items():\n",
    "        print('{} {} images are loaded'.format(len(v), k))\n",
    "    return images_\n",
    "\n",
    "images = load_cats_and_dogs_images('../data/Oxford-IIIT-Pet-Dataset/images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
